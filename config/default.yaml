common:
  #dir: outputs/experiment1
  dir: outputs/cnn7_gamma0.8
  #dir: outputs/${now:%Y-%m-%d}_block5000
  #dir: outputs/experiment_dim5_20220127_v3
  weight_path: trained_model
  load_weight: outputs/2022-02-06/trained_model/tetris_epoch_4610_score34500
  log_path: tensorboard
model:
  name: DQNv2
state:
  dim: 4
train:
  optimizer: Adam
  lr: 1e-3
  replay_memory_size: 30000
  reward_clipping: True
  num_epoch: 5000
  save_interval: 100
  num_decay_epochs: 2000
  initial_epsilon: 1
  final_epsilon: 1e-3
  batch_size: 512
  gamma: 0.8 #0.99
  target_net: False
  reward_list:
    - 0.25 #line cleared
    - -0.0001 #bampiness 
    - 0.0 #hole num
    - -0.1 #height
  max_penalty: -1
tetris:
  board_height: 22
  board_width: 10
  score_list:
    - 0
    - 100
    - 300
    - 700
    - 1300
    - -1300
  max_tetrominoes: 5000
